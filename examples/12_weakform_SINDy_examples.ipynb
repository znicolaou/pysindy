{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weak/Integral SINDy Feature Overview\n",
    "It is often difficult to identify dynamical systems in the presence of substantial noise. Towards that end, a number of publications have used SINDy to identify the weak-formulation (integral formulation) of the system of ODEs or PDEs. This allows one to avoid taking high-order derivatives of noisy data (high-order derivatives of noisy data will amplify the noise). \n",
    "\n",
    "This notebook provides a simple overview of the weak form PDE functionality of PySINDy, following the examples in the PDE-FIND paper (Rudy, Samuel H., Steven L. Brunton, Joshua L. Proctor, and J. Nathan Kutz. \"Data-driven discovery of partial differential equations.\" Science Advances 3, no. 4 (2017): e1602614) and Reinbold, P. A., Gurevich, D. R., & Grigoriev, R. O. (2020). Using noisy or incomplete data to discover models of spatiotemporal dynamics. Physical Review E, 101(1), 010203. Jupyter notebook written by Alan Kaptanoglu.\n",
    "\n",
    "An interactive version of this notebook is available on binder\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/dynamicslab/pysindy/v1.6?filepath=examples/12_weakform_SINDy_examples.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "start=timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T22:20:41.222450Z",
     "start_time": "2020-10-22T22:20:40.308783Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy.io import loadmat\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pysindy.utils.odes import lorenz\n",
    "\n",
    "import pysindy as ps\n",
    "\n",
    "# Ignore matplotlib deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Seed the random number generators for reproducibility\n",
    "np.random.seed(100)\n",
    "\n",
    "# integration keywords for solve_ivp, typically needed for chaotic systems\n",
    "integrator_keywords = {}\n",
    "integrator_keywords['rtol'] = 1e-12\n",
    "integrator_keywords['method'] = 'LSODA'\n",
    "integrator_keywords['atol'] = 1e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test weak form ODE functionality on Lorenz equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x0)' = -9.999 x0 + 9.999 x1\n",
      "(x1)' = 27.992 x0 + -0.999 x1 + -1.000 x0 x2\n",
      "(x2)' = -2.666 x2 + 1.000 x0 x1\n",
      "(x0)' = -10.000 x0 + 10.000 x1\n",
      "(x1)' = 28.000 x0 + -1.000 x1 + -1.000 x0x2\n",
      "(x2)' = -2.667 x2 + 1.000 x0x1\n"
     ]
    }
   ],
   "source": [
    "# Generate measurement data\n",
    "dt = 0.002\n",
    "t_train = np.arange(0, 10, dt)\n",
    "t_train_span = (t_train[0], t_train[-1])\n",
    "u0_train = [-8, 8, 27]\n",
    "u_train = solve_ivp(lorenz, t_train_span, u0_train, \n",
    "                    t_eval=t_train, **integrator_keywords).y.T\n",
    "\n",
    "# Instantiate and fit the SINDy model with u_dot\n",
    "u_dot = ps.FiniteDifference()._differentiate(u_train, t=dt)\n",
    "model = ps.SINDy()\n",
    "model.fit(u_train, x_dot=u_dot, t=dt)\n",
    "model.print()\n",
    "\n",
    "# Define weak form ODE library\n",
    "# defaults to derivative_order = 0 if not specified,\n",
    "# and if spatial_grid is not specified, defaults to None,\n",
    "# which allows weak form ODEs.\n",
    "library_functions = [lambda x: x, lambda x: x * x, lambda x, y: x * y]\n",
    "library_function_names = [lambda x: x, lambda x: x + x, lambda x, y: x + y]\n",
    "ode_lib = ps.WeakPDELibrary(\n",
    "    library_functions=library_functions,\n",
    "    function_names=library_function_names,\n",
    "    spatiotemporal_grid=t_train,\n",
    "    is_uniform=True,\n",
    "    num_pts_per_domain=100,\n",
    "    K=100,\n",
    ")\n",
    "\n",
    "# Instantiate and fit the SINDy model with the integral of u_dot\n",
    "optimizer = ps.SR3(\n",
    "    threshold=0.05, \n",
    "    thresholder=\"l1\", \n",
    "    max_iter=1000, \n",
    "    normalize_columns=True, \n",
    "    tol=1e-1\n",
    ")\n",
    "model = ps.SINDy(feature_library=ode_lib, optimizer=optimizer)\n",
    "model.fit(u_train)\n",
    "model.print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance should improve as the number of sub-domain integrations points increases (numerically approximating the integrals better and better) and number of sub-domains increases (more points for regression). Let's use some noisy Lorenz data and investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 4\t\r"
     ]
    }
   ],
   "source": [
    "# Generate measurement data\n",
    "dt = 0.002\n",
    "t_train = np.arange(0, 10, dt)\n",
    "t_train_span = (t_train[0], t_train[-1])\n",
    "u0_train = [-8, 8, 27]\n",
    "u0_test = [8, 7, 15]\n",
    "u_train = solve_ivp(lorenz, t_train_span, u0_train, \n",
    "                    t_eval=t_train, **integrator_keywords).y.T\n",
    "u_test = solve_ivp(lorenz, t_train_span, u0_test, \n",
    "                   t_eval=t_train, **integrator_keywords).y.T\n",
    "rmse = mean_squared_error(u_train, np.zeros((u_train).shape), squared=False)\n",
    "u_dot_clean = ps.FiniteDifference()._differentiate(u_test, t=dt)\n",
    "u_clean = u_test\n",
    "u_train = u_train + np.random.normal(0, rmse / 5.0, u_train.shape)  # Add 20% noise\n",
    "rmse = mean_squared_error(u_test, np.zeros(u_test.shape), squared=False)\n",
    "u_test = u_test + np.random.normal(0, rmse / 5.0, u_test.shape)  # Add 20% noise\n",
    "u_dot = ps.FiniteDifference()._differentiate(u_test, t=dt)\n",
    "\n",
    "# Same library terms as before\n",
    "library_functions = [lambda x: x, lambda x: x * x, lambda x, y: x * y]\n",
    "library_function_names = [lambda x: x, lambda x: x + x, lambda x, y: x + y]\n",
    "\n",
    "# Scan over the number of integration points and the number of subdomains\n",
    "n = 10\n",
    "errs = np.zeros((n, n))\n",
    "pts_scan = np.linspace(4, 40, n, dtype=int)\n",
    "K_scan = np.linspace(20, 300, n, dtype=int)\n",
    "for i, K in enumerate(K_scan):\n",
    "    for j, pts in enumerate(pts_scan):\n",
    "        print(i,j,end='\\t\\r')\n",
    "        ode_lib = ps.WeakPDELibrary(\n",
    "            library_functions=library_functions,\n",
    "            function_names=library_function_names,\n",
    "            spatiotemporal_grid=t_train,\n",
    "            include_bias=True,\n",
    "            is_uniform=True,\n",
    "            num_pts_per_domain=pts,\n",
    "            K=K,\n",
    "        )\n",
    "        opt = ps.SR3(\n",
    "            threshold=0.05,\n",
    "            thresholder=\"l0\",\n",
    "            max_iter=1000,\n",
    "            normalize_columns=True,\n",
    "            tol=1e-1,\n",
    "        )\n",
    "        u_dot_train_integral = ode_lib.convert_u_dot_integral(u_train)\n",
    "\n",
    "        # Instantiate and fit the SINDy model with the integral of u_dot\n",
    "        model = ps.SINDy(feature_library=ode_lib, optimizer=opt)\n",
    "        model.fit(u_train, quiet=True)\n",
    "        errs[i, j] = np.sqrt(\n",
    "            (\n",
    "                np.sum((u_dot_train_integral - opt.Theta_ @ opt.coef_.T) ** 2)\n",
    "                / np.sum(u_dot_train_integral ** 2)\n",
    "            )\n",
    "            / u_dot_train_integral.shape[0]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance clearly improves as the number of subdomains and number of integrations points increase! We can also see that Lorenz is correctly identified despite ~20% noise levels.\n",
    "\n",
    "\n",
    "The plot belows shows that we can use the weak-formulation to build models that are robust to noise, and additionally indicates convergence as the regression becomes larger and more accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "plt.pcolor(K_scan, pts_scan, errs.T, norm=LogNorm())\n",
    "plt.xlabel('Number of subdomains', fontsize=16)\n",
    "plt.ylabel('Number of subdomain points', fontsize=16)\n",
    "plt.title('Convergence of weak SINDy, hyperparameter scan', fontsize=12)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default scikit-learn functionality for `model.predict` is to return x_dot of the same type as the training data. So for weak form, model.predict returns a prediction of the weak form of x_dot, rather than a prediction of x_dot.\n",
    "\n",
    "We can get around this with a bit of a cheat... inputting the model coefficients from the weak form into the original (not weak) model, and use this to predict!\n",
    "Beware, this requires: \n",
    "1. That the libraries and library ordering are identical in the two models!\n",
    "2. For PDEs, the spatial grids must be identical. This means you need to reuse the library. If you initialize a new PDE library, a new set of subdomains is randomly chosen.\n",
    "3. Note that the candidate libraries $\\Theta$ are fundamentally different in the weak and non-weak models. In the former, all the columns are integrated in time (and for PDEs, also in space)! This means if you forecast the weak model coefficients with the non-weak model, you are using a $\\Theta$ matrix that is very noisy! In other words, using the weak form fixed the issues with noise, but forecasting with the original model still has the noise in $\\Theta$.\n",
    "4. For all these reasons, we will use the error in the coefficients, rather than the error in the predictions, after this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a weak form model\n",
    "ode_lib = ps.WeakPDELibrary(\n",
    "    library_functions=library_functions,\n",
    "    function_names=library_function_names,\n",
    "    spatiotemporal_grid=t_train,\n",
    "    include_bias=True,\n",
    "    is_uniform=True,\n",
    "    num_pts_per_domain=100,\n",
    "    K=5000,\n",
    ")\n",
    "opt = ps.SR3(\n",
    "    threshold=0.5, \n",
    "    thresholder=\"l0\", \n",
    "    max_iter=10000, \n",
    "    normalize_columns=True, \n",
    "    tol=1e-10\n",
    ")\n",
    "model = ps.SINDy(feature_library=ode_lib, optimizer=opt)\n",
    "model.fit(u_train, quiet=True)\n",
    "print(\"Weak form model: \")\n",
    "model.print()\n",
    "\n",
    "# Instantiate and fit a non-weak SINDy model\n",
    "ode_lib = ps.CustomLibrary(\n",
    "    library_functions=library_functions,\n",
    "    function_names=library_function_names,\n",
    "    include_bias=True,\n",
    ")\n",
    "optimizer = ps.SR3(\n",
    "    threshold=0.5, \n",
    "    thresholder=\"l0\", \n",
    "    max_iter=10000, \n",
    "    normalize_columns=True, \n",
    "    tol=1e-10\n",
    ")\n",
    "original_model = ps.SINDy(feature_library=ode_lib, optimizer=optimizer)\n",
    "original_model.fit(u_train, t=dt, quiet=True)\n",
    "print(\"Regular model: \")\n",
    "original_model.print()\n",
    "err_not_weak = np.sqrt(\n",
    "    (np.sum((u_dot - optimizer.Theta_ @ optimizer.coef_.T) ** 2) / np.sum(u_dot ** 2))\n",
    "    / u_dot.shape[0]\n",
    ")\n",
    "\n",
    "u_pred = original_model.simulate(u0_test, t=t_train)\n",
    "u_dot_pred = original_model.predict(u_test)\n",
    "\n",
    "feature_names = ['x', 'y', 'z']\n",
    "optimizer.coef_ = opt.coef_\n",
    "u_dot_weak = original_model.predict(u_test)\n",
    "plt.figure(figsize=(16, 4))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.plot(t_train, u_dot_pred[:, i], \"r\", label=r\"$\\dot{q}$ prediction\")\n",
    "    plt.plot(t_train, u_dot_weak[:, i], \"b\", label=r\"$\\dot{q}$ weak form prediction\")\n",
    "    plt.plot(t_train, u_dot_clean[:, i], \"k\", label=r\"$\\dot{q}$ without added noise\")\n",
    "    plt.grid(True)\n",
    "    plt.ylabel(r'$\\dot{' + feature_names[i] + '}$', fontsize=14)\n",
    "    if i == 2:\n",
    "        plt.legend()\n",
    "\n",
    "u_weak = original_model.simulate(u0_test, t=t_train)\n",
    "plt.figure(figsize=(16, 4))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.plot(t_train, u_test[:, i], \"c\", label=r\"$q$ with added noise\")\n",
    "    plt.plot(t_train, u_pred[:, i], \"r\", label=r\"$q$ prediction\")\n",
    "    plt.plot(t_train, u_weak[:, i], \"b\", label=r\"$q$ weak form prediction\")\n",
    "    plt.plot(t_train, u_clean[:, i], \"k\", label=r\"$q$ without added noise\")\n",
    "    plt.grid(True)\n",
    "    plt.ylabel(feature_names[i], fontsize=14)\n",
    "    plt.xlabel('t', fontsize=14)\n",
    "    if i == 2:\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test weak form PDE functionality on Burgers' equation with 20% noise\n",
    "Note that the weak formulation can be applied to PDEs too. \n",
    "Burgers' equation is\n",
    "$u_t = -uu_x + 0.1 u_{xx}$. We will repeat all the same steps. Although weak-formulation helps with noisy data, we also show that using smoothed finite-differences (or other more advanced differentiation schemes) can also improve robustness to noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('data/burgers.mat')\n",
    "time = np.ravel(data['t'])\n",
    "x = np.ravel(data['x'])\n",
    "u = np.real(data['usol'])\n",
    "dt = time[1] - time[0]\n",
    "dx = x[1] - x[0]\n",
    "rmse = mean_squared_error(u, np.zeros(u.shape), squared=False)\n",
    "# add 20% noise (note the impact on derivatives depends on step size...)\n",
    "u = u + np.random.normal(0, rmse / 5.0, u.shape)\n",
    "\n",
    "# Plot u and u_dot\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.pcolormesh(time, x, u)\n",
    "plt.xlabel('t', fontsize=16)\n",
    "plt.ylabel('x', fontsize=16)\n",
    "plt.title(r'$u(x, t)$', fontsize=16)\n",
    "\n",
    "u_dot = ps.FiniteDifference(axis=1)._differentiate(u, t=dt)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.pcolormesh(time, x, u_dot)\n",
    "plt.xlabel('t', fontsize=16)\n",
    "plt.ylabel('x', fontsize=16)\n",
    "ax = plt.gca()\n",
    "ax.set_yticklabels([])\n",
    "plt.title(r'$\\dot{u}(x, t)$ from FD', fontsize=16)\n",
    "\n",
    "u_dot = ps.SmoothedFiniteDifference(axis=1)._differentiate(u, t=dt)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.pcolormesh(time, x, u_dot)\n",
    "plt.xlabel('t', fontsize=16)\n",
    "plt.ylabel('x', fontsize=16)\n",
    "ax = plt.gca()\n",
    "ax.set_yticklabels([])\n",
    "plt.title(r'$\\dot{u}(x, t)$ from smoothed FD', fontsize=16)\n",
    "plt.show()\n",
    "# See how much SmoothedFiniteDifference improves the derivatives!\n",
    "\n",
    "u = np.reshape(u, (len(x), len(time), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weak form PDE library \n",
    "library_functions = [lambda x: x, lambda x: x * x]\n",
    "library_function_names = [lambda x: x, lambda x: x + x]\n",
    "\n",
    "# Need to define the 2D spatiotemporal grid before calling the library\n",
    "X, T = np.meshgrid(x, time)\n",
    "XT = np.asarray([X, T]).T\n",
    "pde_lib = ps.WeakPDELibrary(library_functions=library_functions, \n",
    "                            function_names=library_function_names, \n",
    "                            derivative_order=2,\n",
    "                            spatiotemporal_grid=XT,\n",
    "                            is_uniform=True, K=1000,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit a weak form model\n",
    "optimizer = ps.SR3(threshold=0.05, thresholder='l0', \n",
    "                   tol=1e-8, normalize_columns=True, max_iter=1000)\n",
    "model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer)\n",
    "model.fit(u, quiet=True)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show that a non-weak form model screws this up badly\n",
    "pde_lib = ps.PDELibrary(library_functions=library_functions, \n",
    "                        function_names=library_function_names, \n",
    "                        derivative_order=2, spatial_grid=x,\n",
    "                        include_bias=False,\n",
    "                        is_uniform=True)\n",
    "\n",
    "# Fit and predict with the non-weak model\n",
    "opt = ps.SR3(threshold=0.05, thresholder='l0', \n",
    "             tol=1e-10, normalize_columns=True, \n",
    "             max_iter=1000)\n",
    "model_for_prediction = ps.SINDy(feature_library=pde_lib, optimizer=opt)\n",
    "model_for_prediction.fit(u)\n",
    "\n",
    "# Prints a very wrong model\n",
    "model_for_prediction.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The takeaway here is that the weak formulation drastically improved our system identification on the Burgers' equation with added noise. The weak formulation can handle even more than 20% noise here, although then a fairly large value for K is required to obtain a decent system identification. This is required for some of the examples below, and the downside is that this slows down the code considerably. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test weak form PDE functionality on nonlinear diffusion with mixed function-derivative terms\n",
    "Unlike the other PDE examples shown, this contains mixed terms like $uu_{xx}$, so this is a nice check the full PDE functionality works,\n",
    "$$ u_ t = u u_{xx}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffuse (t, u, dx, nx):\n",
    "    u = np.reshape(u, nx)\n",
    "    du = ps.differentiation.SpectralDerivative(\n",
    "            d=2, axis=0\n",
    "         )._differentiate(u, dx)\n",
    "    return np.reshape(u * du, nx)\n",
    "\n",
    "N = 200\n",
    "h0 = 1.0\n",
    "L = 5\n",
    "T = 1\n",
    "\n",
    "t = np.linspace(0, T, N)\n",
    "x = np.arange(0, N) * L / N\n",
    "\n",
    "ep = 0.5 * h0\n",
    "y0 = np.reshape(h0 + ep * np.cos(4 * np.pi / L * x) \n",
    "                + ep * np.cos(2 * np.pi / L * x), N)\n",
    "dx = x[1] - x[0]\n",
    "\n",
    "sol = solve_ivp(diffuse, (t[0], t[-1]), \n",
    "                y0=y0, t_eval=t, args=(dx, N),\n",
    "                **integrator_keywords)\n",
    "\n",
    "u_shaped_noiseless = np.reshape(sol.y, (N, N, 1))\n",
    "u_dot_noiseless = ps.FiniteDifference(\n",
    "    d=1, axis=1\n",
    ")._differentiate(u_shaped_noiseless,t)\n",
    "\n",
    "ep = 0.01 * np.min(sol.y)\n",
    "u_shaped_noisy = u_shaped_noiseless + 2 * ep * (\n",
    "    0.5 - np.random.random(size=(N, N, 1))\n",
    ")\n",
    "u_dot_noisy = ps.FiniteDifference(\n",
    "    d=1, axis=1)._differentiate(u_shaped_noisy, t)\n",
    "\n",
    "# Plot u and u_dot\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(u_dot_noiseless[:, :, 0])\n",
    "plt.colorbar()\n",
    "plt.xlabel('t', fontsize=16)\n",
    "plt.ylabel('x', fontsize=16)\n",
    "plt.title(r'$u(x, t)$', fontsize=16)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(u_dot_noisy[:, :, 0])\n",
    "plt.colorbar()\n",
    "plt.xlabel('t', fontsize=16)\n",
    "plt.ylabel('x', fontsize=16)\n",
    "ax = plt.gca()\n",
    "plt.title(r'$\\dot{u}(x, t)$ from finite differences', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regular PDELibrary fails for noisy data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_functions = [\n",
    "    lambda x: x,\n",
    "]\n",
    "library_function_names = [\n",
    "    lambda x: x,\n",
    "]\n",
    "\n",
    "pde_lib = ps.PDELibrary(\n",
    "    library_functions=library_functions,\n",
    "    function_names=library_function_names,\n",
    "    derivative_order=2,\n",
    "    spatial_grid=x,\n",
    "    is_uniform=True,\n",
    ")\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "optimizer = ps.STLSQ(threshold=0.1, alpha=1e-5, normalize_columns=False)\n",
    "model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer, feature_names=['u'])\n",
    "model.fit(u_shaped_noiseless, \n",
    "          x_dot=np.reshape(u_dot_noiseless, (N ** 2, 1)))\n",
    "model.print()\n",
    "\n",
    "optimizer = ps.STLSQ(threshold=0.1, alpha=1e-5, normalize_columns=False)\n",
    "model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer, feature_names=['u'])\n",
    "model.fit(u_shaped_noisy, \n",
    "          x_dot=np.reshape(u_dot_noisy, (N ** 2, 1)))\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WeakPDELibrary works great for noisy data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_functions = [\n",
    "    lambda x: x,\n",
    "]\n",
    "library_function_names = [\n",
    "    lambda x: x,\n",
    "]\n",
    "\n",
    "X, T = np.meshgrid(x, t, indexing='ij')\n",
    "XT = np.transpose([X, T], [1, 2, 0])\n",
    "pde_lib = ps.WeakPDELibrary(\n",
    "    library_functions=library_functions,\n",
    "    function_names=library_function_names,\n",
    "    derivative_order=2,\n",
    "    spatiotemporal_grid=XT,\n",
    "    K=100,\n",
    "    is_uniform=True,\n",
    "    num_pts_per_domain=30,\n",
    ")\n",
    "\n",
    "np.random.seed(100)\n",
    "optimizer = ps.STLSQ(threshold=0.1, alpha=1e-5, normalize_columns=False)\n",
    "model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer, feature_names=['u'])\n",
    "model.fit(u_shaped_noiseless)\n",
    "model.print()\n",
    "\n",
    "optimizer = ps.STLSQ(threshold=0.1, alpha=1e-5, normalize_columns=False)\n",
    "model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer, feature_names=['u'])\n",
    "model.fit(u_shaped_noisy)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test weak-formulation PDE functionality on the Kuramoto-Sivashinsky equation\n",
    "The Kuramoto-Sivashinsky equation is\n",
    "$u_t = -uu_x - u_{xx} - u_{xxxx}$. We will skip noisy data for now, since we have already illustrated the pitfalls and performance with the weak form. We will revisit noisy data for the 2D reaction-diffusion example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and plot the data\n",
    "data = loadmat('data/kuramoto_sivishinky.mat')\n",
    "time = np.ravel(data['tt'])\n",
    "x = np.ravel(data['x'])\n",
    "u = data['uu']\n",
    "dt = time[1] - time[0]\n",
    "dx = x[1] - x[0]\n",
    "\n",
    "# Plot u and u_dot\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolormesh(time, x, u)\n",
    "plt.xlabel('t', fontsize=16)\n",
    "plt.ylabel('x', fontsize=16)\n",
    "plt.title(r'$u(x, t)$', fontsize=16)\n",
    "\n",
    "u_dot = ps.FiniteDifference(axis=1)._differentiate(u, t=dt)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolormesh(time, x, u_dot)\n",
    "plt.xlabel('t', fontsize=16)\n",
    "plt.ylabel('x', fontsize=16)\n",
    "ax = plt.gca()\n",
    "ax.set_yticklabels([])\n",
    "plt.title(r'$\\dot{u}(x, t)$', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "u = u.reshape(len(x), len(time), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weak form PDE library\n",
    "library_functions = [lambda x: x, lambda x: x * x]\n",
    "library_function_names = [lambda x: x, lambda x: x + x]\n",
    "X, T = np.meshgrid(x, time)\n",
    "XT = np.asarray([X, T]).T\n",
    "pde_lib = ps.WeakPDELibrary(\n",
    "    library_functions=library_functions,\n",
    "    function_names=library_function_names,\n",
    "    derivative_order=4,\n",
    "    spatiotemporal_grid=XT,\n",
    "    H_xt=20,\n",
    "    include_bias=True,\n",
    "    is_uniform=True,\n",
    "    K=200,\n",
    "    num_pts_per_domain=200,\n",
    "    include_interaction=True,\n",
    "    periodic=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run optimizers \n",
    "optimizer = ps.STLSQ(threshold=0.4, alpha=0.05, normalize_columns=True)\n",
    "model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer)\n",
    "model.fit(u, quiet=True)\n",
    "model.print()\n",
    "\n",
    "optimizer = ps.SR3(\n",
    "    threshold=0.8, max_iter=1000,\n",
    "    thresholder=\"l0\", normalize_columns=True\n",
    ")\n",
    "model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer)\n",
    "model.fit(u, quiet=True)\n",
    "model.print()\n",
    "\n",
    "optimizer = ps.SR3(\n",
    "    threshold=0.2, max_iter=1000,\n",
    "    thresholder=\"l1\", normalize_columns=True\n",
    ")\n",
    "model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer)\n",
    "model.fit(u, quiet=True)\n",
    "model.print()\n",
    "\n",
    "optimizer = ps.SSR(normalize_columns=True, kappa=1e-20, max_iter=20)\n",
    "model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer)\n",
    "model.fit(u, quiet=True)\n",
    "model.print()\n",
    "\n",
    "optimizer = ps.SSR(criteria='model_residual', normalize_columns=True, \n",
    "                   kappa=1e-20, max_iter=20)\n",
    "model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer)\n",
    "model.fit(u, quiet=True)\n",
    "model.print()\n",
    "\n",
    "optimizer = ps.FROLS(normalize_columns=True, kappa=1e-20)\n",
    "model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer)\n",
    "model.fit(u, quiet=True)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Okay, so all the optimizers essentially capture the model but often have some much smaller \"extra\" terms.**\n",
    "The best way to deal with these spurious terms is to use ensembling, i.e. the generation of many models by sub-sampling the data, or sub-sampling the SINDy candidate library. See notebook 13 for many examples of how to use these methods. \n",
    "\n",
    "You can also deal with this by scanning over the hyperparameters for each method although this is more laborious for the user. \n",
    "\n",
    "**Next we try the SR3 optimizer on the same data but with added noise of varying levels to illustrate the robustness to noisy data.**\n",
    "Ideally, we would cross-validate over 10-20 noise instantiations, but with this high-dimensional data this can be computationally slow. We compute the coefficient model errors defined through\n",
    "$$\\Delta\\xi_{u_{xx}} = \\|\\xi_{u_{xx}}^{true} - \\xi_{u_{xx}}^{pred}\\| / \\|\\xi_{u_{xx}}^{true}\\| =  \\|-1 - \\xi_{u_{xx}}^{pred}\\|,$$\n",
    "and similarly for the other coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average SR3 performance as function of the noise level.\n",
    "cross_val_runs = 1\n",
    "u = np.squeeze(u)\n",
    "rmse = mean_squared_error(u, np.zeros(u.shape), squared=False)\n",
    "noise_levels = np.linspace(0, rmse / 2.0, 5)\n",
    "delta_c1 = np.zeros((cross_val_runs, len(noise_levels)))\n",
    "delta_c2 = np.zeros((cross_val_runs, len(noise_levels)))\n",
    "delta_c3 = np.zeros((cross_val_runs, len(noise_levels)))\n",
    "pde_lib = ps.WeakPDELibrary(\n",
    "    library_functions=library_functions,\n",
    "    function_names=library_function_names,\n",
    "    derivative_order=4,\n",
    "    spatiotemporal_grid=XT,\n",
    "    K=400,\n",
    "    is_uniform=True,\n",
    "    num_pts_per_domain=100,\n",
    ")\n",
    "optimizer = ps.SR3(\n",
    "    threshold=0.5, max_iter=20, tol=1e-10, \n",
    "    thresholder=\"l0\", normalize_columns=True\n",
    ")\n",
    "model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer)\n",
    "for i in range(cross_val_runs):\n",
    "    for j, noise in enumerate(noise_levels):\n",
    "        u_noisy = u + np.random.normal(0, noise, u.shape)\n",
    "        u_noisy = np.reshape(u_noisy, (len(x), len(time), 1))\n",
    "        model.fit(u_noisy, quiet=True)\n",
    "        model.print()\n",
    "        c1 = abs(optimizer.coef_[0, 6])\n",
    "        c2 = abs(optimizer.coef_[0, 3])\n",
    "        c3 = abs(optimizer.coef_[0, 5])\n",
    "        delta_c1[i, j] = abs(abs(c1 - 1.0) / c1)\n",
    "        delta_c2[i, j] = abs(abs(c2 - 1.0) / c2)\n",
    "        delta_c3[i, j] = abs(abs(c3 - 1.0) / c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have computed the error in the model coefficients at each noise level, we plot the results.\n",
    "We show below that the weak form nicely works for even 50% Gaussian noise added to every point, showing the power of the weak-formulation for robust system identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mean and std over the validation runs\n",
    "delta_c1_mean = np.nanmean(delta_c1, axis=0)\n",
    "delta_c2_mean = np.nanmean(delta_c2, axis=0)\n",
    "delta_c3_mean = np.nanmean(delta_c3, axis=0)\n",
    "\n",
    "delta_c1_std = np.nanstd(delta_c1, axis=0)\n",
    "delta_c2_std = np.nanstd(delta_c2, axis=0)\n",
    "delta_c3_std = np.nanstd(delta_c3, axis=0)\n",
    "\n",
    "# Plot average and standard deviations of the coefficient errors\n",
    "plt.figure()\n",
    "plt.errorbar(\n",
    "    noise_levels / rmse * 100,\n",
    "    y=delta_c1_mean,\n",
    "    yerr=delta_c1_std,\n",
    "    color=\"r\",\n",
    "    fmt=\"o\",\n",
    "    label=r\"$\\Delta\\xi_{uu_x}$\",\n",
    ")\n",
    "plt.errorbar(\n",
    "    noise_levels / rmse * 100,\n",
    "    y=delta_c2_mean,\n",
    "    yerr=delta_c2_std,\n",
    "    color=\"b\",\n",
    "    fmt=\"o\",\n",
    "    label=r\"$\\Delta\\xi_{u_{xx}}$\",\n",
    ")\n",
    "plt.errorbar(\n",
    "    noise_levels / rmse * 100,\n",
    "    y=delta_c3_mean,\n",
    "    yerr=delta_c3_std,\n",
    "    color=\"k\",\n",
    "    fmt=\"o\",\n",
    "    label=r\"$\\Delta\\xi_{u_{xxxx}}$\",\n",
    ")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend(\n",
    "    fontsize=14, loc=\"upper left\", ncol=3\n",
    ")\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.grid(True)\n",
    "ax = plt.gca()\n",
    "ax.set_ylim(1e-5, 1)\n",
    "plt.xlabel('% training noise', fontsize=16)\n",
    "plt.ylabel('Coefficient errors', fontsize=16)\n",
    "plt.savefig(\"SR3_weakformPDE_KS.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test weak form PDE functionality on Reaction-Diffusion system\n",
    "We now demonstrate another more advanced example - using the weak formulation of SINDy to robustly identify a 2D PDE.\n",
    "This 2D system is significantly more complicated. The reaction-diffusion system exhibits spiral waves on a periodic domain,and the PDEs are:\n",
    "$$u_t = 0.1\\nabla^2 u + (1-A^2)u +\\beta A^2v$$\n",
    "$$v_t = 0.1\\nabla^2 v - \\beta A^2 u + (1-A^2)v$$\n",
    "$$A^2 = u^2 + v^2.$$\n",
    "The main change will be a significantly larger library... cubic terms in (u, v) and all their first and second order derivatives. We will also need to generate the data because saving a high-resolution form of the data makes a fairly large file. See the Example 10 Jupyter notebook for the non-weak-form system identification of the reaction-diffusion system.\n",
    "\n",
    "Note that the Rudy PDE-FIND paper and Messenger Weak SINDy paper use 256 spatial points in each spatial direction, but Reinbold weak SINDy PRE paper uses 512 points in each direction. We will try and get away with only 64 points in each direction for speed (with normal PDE-FIND this would be a liability because the high order derivatives are very noisy), and still show robustness to ~ 10% noise levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.fft import fft2, ifft2\n",
    "\n",
    "# Define the reaction-diffusion PDE in the Fourier (kx, ky) space\n",
    "def reaction_diffusion(t, uvt, K22, d1, d2, beta, n, N):\n",
    "    ut = np.reshape(uvt[:N], (n, n))\n",
    "    vt = np.reshape(uvt[N : 2 * N], (n, n))\n",
    "    u = np.real(ifft2(ut))\n",
    "    v = np.real(ifft2(vt))\n",
    "    u3 = u ** 3\n",
    "    v3 = v ** 3\n",
    "    u2v = (u ** 2) * v\n",
    "    uv2 = u * (v ** 2)\n",
    "    utrhs = np.reshape((fft2(u - u3 - uv2 + beta * u2v + beta * v3)), (N, 1))\n",
    "    vtrhs = np.reshape((fft2(v - u2v - v3 - beta * u3 - beta * uv2)), (N, 1))\n",
    "    uvt_reshaped = np.reshape(uvt, (len(uvt), 1))\n",
    "    uvt_updated = np.squeeze(\n",
    "        np.vstack(\n",
    "            (-d1 * K22 * uvt_reshaped[:N] + utrhs, \n",
    "             -d2 * K22 * uvt_reshaped[N:] + vtrhs)\n",
    "        )\n",
    "    )\n",
    "    return uvt_updated\n",
    "\n",
    "\n",
    "# Generate the data\n",
    "t = np.linspace(0, 10, int(10 / 0.1))\n",
    "d1 = 0.1\n",
    "d2 = 0.1\n",
    "beta = 1.0\n",
    "L = 20  # Domain size in X and Y directions\n",
    "n = 64  # Number of spatial points in each direction\n",
    "N = n * n\n",
    "x_uniform = np.linspace(-L / 2, L / 2, n + 1)\n",
    "x = x_uniform[:n]\n",
    "y = x_uniform[:n]\n",
    "n2 = int(n / 2)\n",
    "# Define Fourier wavevectors (kx, ky)\n",
    "kx = (2 * np.pi / L) * np.hstack((np.linspace(0, n2 - 1, n2), \n",
    "                                  np.linspace(-n2, -1, n2)))\n",
    "ky = kx\n",
    "# Get 2D meshes in (x, y) and (kx, ky)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "KX, KY = np.meshgrid(kx, ky)\n",
    "K2 = KX ** 2 + KY ** 2\n",
    "K22 = np.reshape(K2, (N, 1))\n",
    "\n",
    "m = 1  # number of spirals\n",
    "\n",
    "# define our solution vectors\n",
    "u = np.zeros((len(x), len(y), len(t)))\n",
    "v = np.zeros((len(x), len(y), len(t)))\n",
    "\n",
    "# Initial conditions\n",
    "u[:, :, 0] = np.tanh(np.sqrt(X ** 2 + Y ** 2)) * np.cos(\n",
    "    m * np.angle(X + 1j * Y) - (np.sqrt(X ** 2 + Y ** 2))\n",
    ")\n",
    "v[:, :, 0] = np.tanh(np.sqrt(X ** 2 + Y ** 2)) * np.sin(\n",
    "    m * np.angle(X + 1j * Y) - (np.sqrt(X ** 2 + Y ** 2))\n",
    ")\n",
    "\n",
    "# uvt is the solution vector in Fourier space, so below\n",
    "# we are initializing the 2D FFT of the initial condition, uvt0\n",
    "uvt0 = np.squeeze(\n",
    "    np.hstack(\n",
    "        (np.reshape(fft2(u[:, :, 0]), (1, N)), \n",
    "         np.reshape(fft2(v[:, :, 0]), (1, N)))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Solve the PDE in the Fourier space, where it reduces to system of ODEs\n",
    "uvsol = solve_ivp(\n",
    "    reaction_diffusion, \n",
    "    (t[0], t[-1]), \n",
    "    y0=uvt0, \n",
    "    t_eval=t, \n",
    "    args=(K22, d1, d2, beta, n, N)\n",
    ")\n",
    "uvsol = uvsol.y\n",
    "\n",
    "# Reshape things and ifft back into (x, y, t) space from (kx, ky, t) space\n",
    "for j in range(len(t)):\n",
    "    ut = np.reshape(uvsol[:N, j], (n, n))\n",
    "    vt = np.reshape(uvsol[N:, j], (n, n))\n",
    "    u[:, :, j] = np.real(ifft2(ut))\n",
    "    v[:, :, j] = np.real(ifft2(vt))\n",
    "\n",
    "# Plot to check if spiral is nicely reproduced\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolor(X, Y, u[:, :, 10])\n",
    "plt.xlabel('x', fontsize=16)\n",
    "plt.ylabel('y', fontsize=16)\n",
    "plt.title('u(x, y, t=0.5)', fontsize=16)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolor(X, Y, v[:, :, 10])\n",
    "plt.xlabel('x', fontsize=16)\n",
    "plt.ylabel('y', fontsize=16)\n",
    "ax = plt.gca()\n",
    "ax.set_yticklabels([])\n",
    "plt.title('v(x, y, t=0.5)', fontsize=16)\n",
    "\n",
    "dt = t[1] - t[0]\n",
    "dx = x[1] - x[0]\n",
    "dy = y[1] - y[0]\n",
    "\n",
    "u_sol = u\n",
    "v_sol = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.zeros((n, n, len(t), 2))\n",
    "u[:, :, :, 0] = u_sol\n",
    "u[:, :, :, 1] = v_sol\n",
    "\n",
    "# Odd polynomial terms in (u, v), up to second order derivatives in (u, v)\n",
    "library_functions = [\n",
    "    lambda x: x,\n",
    "    lambda x: x * x * x,\n",
    "    lambda x, y: x * y * y,\n",
    "    lambda x, y: x * x * y,\n",
    "]\n",
    "library_function_names = [\n",
    "    lambda x: x,\n",
    "    lambda x: x + x + x,\n",
    "    lambda x, y: x + y + y,\n",
    "    lambda x, y: x + x + y,\n",
    "]\n",
    "\n",
    "# Need to define the 2D spatial grid before calling the library\n",
    "X, Y, T = np.meshgrid(x, y, t, indexing='ij')\n",
    "XYT = np.transpose([X, Y, T], [1, 2, 3, 0])\n",
    "weak_lib = ps.WeakPDELibrary(\n",
    "    library_functions=library_functions,\n",
    "    function_names=library_function_names,\n",
    "    derivative_order=2,\n",
    "    spatiotemporal_grid=XYT,\n",
    "    is_uniform=True,\n",
    "    periodic=True,\n",
    "    K=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the 2D reaction-diffusion equation, weak form style!\n",
    "optimizer = ps.STLSQ(threshold=0.05, alpha=1e-5, normalize_columns=True)\n",
    "model = ps.SINDy(feature_library=weak_lib, optimizer=optimizer)\n",
    "model.fit(u, quiet=True)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we have captured the essential terms in the clean data case... can we repeat with some added noise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to increase the weak form mesh resolution a bit if data is noisy\n",
    "weak_lib = ps.WeakPDELibrary(\n",
    "    library_functions=library_functions,\n",
    "    function_names=library_function_names,\n",
    "    derivative_order=2,\n",
    "    spatiotemporal_grid=XYT,\n",
    "    K=400,\n",
    "    is_uniform=True,\n",
    "    periodic=True\n",
    ")\n",
    "\n",
    "# Initialize noisy data\n",
    "rmse = mean_squared_error(u.flatten(), np.zeros(u.size), squared=False)\n",
    "u_noisy = u + np.random.normal(0, rmse / 50.0, u.shape)  # Add 2% noise\n",
    "\n",
    "# Fit the 2D reaction-diffusion equation with noise, weak form style!\n",
    "optimizer = ps.STLSQ(threshold=0.05, alpha=1e-5, normalize_columns=True)\n",
    "model = ps.SINDy(feature_library=weak_lib, optimizer=optimizer)\n",
    "model.fit(u_noisy, quiet=True)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weak formulation works adequately with noise, but requires a relatively large K and takes some time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test weak form PDE functionality on 3D Reaction-Diffusion system\n",
    "Can even use weak-form for 3D PDEs although this is getting computationally intensive! \n",
    "\n",
    "We will use a 3D reaction-diffusion equation called the Gray-Scott Equation. We are folllowing the example in Section 3.3.3 of Maddu, S., Cheeseman, B. L., Sbalzarini, I. F., & Müller, C. L. (2019). Stability selection enables robust learning of partial differential equations from limited noisy data. arXiv preprint arXiv:1907.07810. ([Link](https://arxiv.org/pdf/1907.07810.pdf)).\n",
    "$$u_t = D_u\\nabla^2 u - uv^2 + 0.014(1-u)$$\n",
    "$$v_t = D_v\\nabla^2 v + uv^2 - 0.067 v$$\n",
    "We will need to generate some low-resolution data, because the memory requirements are very significant for a fully 3D problem. We can still get a pretty good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.fft import fftn, ifftn\n",
    "\n",
    "# Define the reaction-diffusion PDE in the Fourier (kx, ky, kz) space\n",
    "def reaction_diffusion(t, uvt, K22, d1, d2, n, N):\n",
    "    ut = np.reshape(uvt[:N], (n, n, n))\n",
    "    vt = np.reshape(uvt[N : 2 * N], (n, n, n))\n",
    "    u = np.real(ifftn(ut, axes=[0, 1, 2]))\n",
    "    v = np.real(ifftn(vt, axes=[0, 1, 2]))\n",
    "    uv2 = u * (v ** 2)\n",
    "    utrhs = np.reshape((fftn(0.014 * (1 - u) - uv2, axes=[0, 1, 2])), (N, 1))\n",
    "    vtrhs = np.reshape((fftn(uv2 - 0.067 * v, axes=[0, 1, 2])), (N, 1))\n",
    "    uvt_reshaped = np.reshape(uvt, (len(uvt), 1))\n",
    "    uvt_updated = np.squeeze(\n",
    "        np.vstack(\n",
    "            (-d1 * K22 * uvt_reshaped[:N] + utrhs, \n",
    "             -d2 * K22 * uvt_reshaped[N:] + vtrhs)\n",
    "        )\n",
    "    )\n",
    "    return uvt_updated\n",
    "\n",
    "\n",
    "# Generate the data\n",
    "dt = 0.1\n",
    "t = np.linspace(0, 10, int(10 / dt))\n",
    "d1 = 2e-2\n",
    "d2 = 1e-2\n",
    "L = 2.5  # Domain size in X, Y, Z directions\n",
    "n = 32  # Number of spatial points in each direction\n",
    "N = n * n * n\n",
    "x_uniform = np.linspace(-L / 2, L / 2, n + 1)\n",
    "x = x_uniform[:n]\n",
    "y = x_uniform[:n]\n",
    "z = x_uniform[:n]\n",
    "n2 = int(n / 2)\n",
    "# Define Fourier wavevectors (kx, ky, kz)\n",
    "kx = (2 * np.pi / L) * np.hstack((np.linspace(0, n2 - 1, n2), \n",
    "                                  np.linspace(-n2, -1, n2)))\n",
    "ky = kx\n",
    "kz = kx\n",
    "# Get 3D meshes in (x, y, z) and (kx, ky, kz)\n",
    "X, Y, Z = np.meshgrid(x, y, z, indexing=\"ij\")\n",
    "KX, KY, KZ = np.meshgrid(kx, ky, kz, indexing=\"ij\")\n",
    "K2 = KX ** 2 + KY ** 2 + KZ ** 2\n",
    "K22 = np.reshape(K2, (N, 1))\n",
    "\n",
    "m = 3  # number of spirals\n",
    "\n",
    "# define our solution vectors\n",
    "u = np.zeros((n, n, n, len(t)))\n",
    "v = np.zeros((n, n, n, len(t)))\n",
    "\n",
    "# Initial conditions\n",
    "u[:, :, :, 0] = np.tanh(np.sqrt(X ** 2 + Y ** 2 + Z ** 2)) * np.cos(\n",
    "    m * np.angle(X + 1j * Y) - (np.sqrt(X ** 2 + Y ** 2 + Z ** 2))\n",
    ")\n",
    "v[:, :, :, 0] = np.tanh(np.sqrt(X ** 2 + Y ** 2 + Z ** 2)) * np.sin(\n",
    "    m * np.angle(X + 1j * Y) - (np.sqrt(X ** 2 + Y ** 2 + Z ** 2))\n",
    ")\n",
    "\n",
    "# uvt is the solution vector in Fourier space, so below\n",
    "# we are initializing the 2D FFT of the initial condition, uvt0\n",
    "uvt0 = np.squeeze(\n",
    "    np.hstack(\n",
    "        (\n",
    "            np.reshape(fftn(u[:, :, :, 0], axes=[0, 1, 2]), (1, N)),\n",
    "            np.reshape(fftn(v[:, :, :, 0], axes=[0, 1, 2]), (1, N)),\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Solve the PDE in the Fourier space, where it reduces to system of ODEs\n",
    "uvsol = solve_ivp(\n",
    "    reaction_diffusion, \n",
    "    (t[0], t[-1]), \n",
    "    y0=uvt0, \n",
    "    t_eval=t, \n",
    "    args=(K22, d1, d2, n, N)\n",
    ")\n",
    "uvsol = uvsol.y\n",
    "\n",
    "# Reshape things and ifft back into (x, y, z, t) space from (kx, ky, kz, t) space\n",
    "for j in range(len(t)):\n",
    "    ut = np.reshape(uvsol[:N, j], (n, n, n))\n",
    "    vt = np.reshape(uvsol[N:, j], (n, n, n))\n",
    "    u[:, :, :, j] = np.real(ifftn(ut, axes=[0, 1, 2]))\n",
    "    v[:, :, :, j] = np.real(ifftn(vt, axes=[0, 1, 2]))\n",
    "\n",
    "# Plot to check if spiral is nicely reproduced\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pcolor(X[:, :, 0], Y[:, :, 0], u[:, :, 0, 0])\n",
    "plt.xlabel('x', fontsize=16)\n",
    "plt.ylabel('y', fontsize=16)\n",
    "plt.title('u(x, y, z=0, t=0)', fontsize=16)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pcolor(X[:, :, 0], Y[:, :, 0], v[:, :, 0, 0])\n",
    "plt.xlabel('x', fontsize=16)\n",
    "plt.ylabel('y', fontsize=16)\n",
    "ax = plt.gca()\n",
    "ax.set_yticklabels([])\n",
    "plt.title('v(x, y, z=0, t=0)', fontsize=16)\n",
    "\n",
    "dt = t[1] - t[0]\n",
    "dx = x[1] - x[0]\n",
    "dy = y[1] - y[0]\n",
    "dz = z[1] - z[0]\n",
    "\n",
    "u_sol = u\n",
    "v_sol = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = t\n",
    "u = np.zeros((n, n, n, len(time), 2))\n",
    "u[:, :, :, :, 0] = u_sol\n",
    "u[:, :, :, :, 1] = v_sol\n",
    "u_dot = ps.FiniteDifference(axis=3)._differentiate(u, dt)\n",
    "\n",
    "# Odd polynomial terms in (u, v), up to second order derivatives in (u, v)\n",
    "library_functions = [\n",
    "    lambda x: x,\n",
    "    lambda x: x * x * x,\n",
    "    lambda x, y: x * y * y,\n",
    "    lambda x, y: x * x * y,\n",
    "]\n",
    "library_function_names = [\n",
    "    lambda x: x,\n",
    "    lambda x: x + x + x,\n",
    "    lambda x, y: x + y + y,\n",
    "    lambda x, y: x + x + y,\n",
    "]\n",
    "\n",
    "# Need to define the 2D spatial grid before calling the library\n",
    "X, Y, Z, T = np.meshgrid(x, y, z, time, indexing=\"ij\")\n",
    "spatiotemporal_grid = np.asarray([X, Y, Z, T])\n",
    "spatiotemporal_grid = np.transpose(spatiotemporal_grid, axes=[1, 2, 3, 4, 0])\n",
    "pde_lib = ps.WeakPDELibrary(\n",
    "    library_functions=library_functions,\n",
    "    function_names=library_function_names,\n",
    "    derivative_order=2,\n",
    "    spatiotemporal_grid=spatiotemporal_grid,\n",
    "    is_uniform=True,\n",
    "    num_pts_per_domain=20,\n",
    "    include_interaction=False,\n",
    "    include_bias=True,\n",
    "    periodic=True,\n",
    "    H_xt=[L/4,L/4,L/4,1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the 3D reaction-diffusion equation\n",
    "optimizer = ps.SR3(threshold=1e-4, normalize_columns=True, max_iter=50)\n",
    "model = ps.SINDy(feature_library=pde_lib, optimizer=optimizer)\n",
    "model.fit(u, quiet=True)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=timeit.default_timer()\n",
    "print(stop-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "296.475px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
